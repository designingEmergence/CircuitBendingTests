{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "mount_file_id": "1jXFm0PrjajomYLYBHFm9nr9nTs7r86Jw",
      "authorship_tag": "ABX9TyMLQRwKhC4TJD9oml/zlDr1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/designingEmergence/CircuitBendingTests/blob/main/colab_notebooks/Circuit_Bend_LLMs_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Circuit Bending LLMs - Test\n",
        "\n"
      ],
      "metadata": {
        "id": "pik_w-5ON3x_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Circuit Bending\n",
        "Circuit bending is the art of taking an old, sound making toy and hacking the circuits to produce a different sound than expected. To circuit bend something, you open it up, find the circuit board that is responsible for making the sound, lick your finger and touch the resistors and components of the circuit while pressing the sound-activating buttons. The effect you get is a glitchy, altered version of the original sound, since you are short circuiting the transistors and changing the resistance of the analog circuit with your wet finger. Circuit bending is a great way to get unexpected and unique sounds by essentially glitching the circuit. Hmm.. glitching the circuit… Aha! I wonder if I can circuit bend an AI model to make it behave “drunk”.\n",
        "\n",
        "### Circuit Bending AI - The Theory\n",
        "\n",
        "In theory, there are a lot of parallels between circuit bending old toys and AI models. Just like, an old toy, you can open up an AI model and expose the weights of its neural network, which are essentially the circuit board of the model. These weights define how the AI model operates. The reason Stable Diffusion produces an image of an apple when you prompt “Photo of Apple, close up” is because the weights have been set to a precise configuration by hours and hours of training. You can then lick your metaphorical finger and “bend” the circuit by changing the weights of the model, which will produce glitchy and unexpected outputs!\n",
        "\n",
        "### Purpose of this notebook\n",
        "\n",
        "Here we are testing if its possible to manipulate the weights of LLMs and run the manipulated version of the LLM.\n",
        "\n",
        "### Pre-Requisites\n",
        "\n",
        "- Download an LLM. Here I am using Lllama3.2-1B. You can download the model directly from the [llama hugging face space](https://huggingface.co/meta-llama/Llama-3.2-1B/tree/main)\n",
        "- Upload this model to either Google Drive or directly to the runtime (although the model is large so I recommend Google Drive)\n",
        "\n",
        "Note: You can use any LLM that is hugging face transformer compatible, it doesn't have to be Llama.\n"
      ],
      "metadata": {
        "id": "_dT81Q6dveMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tc4wmfpsOGaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Install PyTorch (if not already installed)\n",
        "# Colab usually comes with PyTorch pre-installed, but you can update it if needed.\n",
        "\n",
        "!pip install torch transformers"
      ],
      "metadata": {
        "id": "nyU7V1dgOnjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Import libraries\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "-OOjjkNEOvn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Set up paths\n",
        "\n",
        "drive_model_path = '/content/drive/MyDrive/Projects/Circuit_Bending_AI/models/Llama-3.2-1B-hf'\n",
        "modified_model_path = '/content/drive/MyDrive/Projects/Circuit_Bending_AI/models/Llama-3.2-1B-hf_mod'\n",
        "\n",
        "log_directory = '/content/drive/MyDrive/Projects/Circuit_Bending_AI/experiment-logs'\n",
        "os.makedirs(log_directory, exist_ok=True)\n",
        "log_file = os.path.join(log_directory, 'experiment_log.csv')\n",
        "\n",
        "#initialize CSV file with headers if it doesn't exist\n",
        "if not os.path.isfile(log_file):\n",
        "    with open(log_file, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['timestamp', 'model_name', 'layer_name', 'noise_factor', 'prompt', 'output'])\n",
        "\n"
      ],
      "metadata": {
        "id": "8kty8lmMPHdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define functions\n",
        "\n",
        "# Load model and tokenizer from google drive\n",
        "def load_model_and_tokenizer_from_drive(path):\n",
        "  print(f\"Loading model and tokenizer from {path}....\")\n",
        "  model = AutoModelForCausalLM.from_pretrained(path)\n",
        "  tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "  print(\"Model and tokenizer loaded succesfully\")\n",
        "  return tokenizer, model\n",
        "\n",
        "# Bend model weights\n",
        "def bend_weights(model, noise_factor=0.01, layer_query=None):\n",
        "  print(\"Bending model weights...\")\n",
        "   # Create a copy of the state_dict to prevent changes to the original model\n",
        "  state_dict = model.state_dict()\n",
        "  modified_state_dict = {k: v.clone() for k, v in state_dict.items()}\n",
        "\n",
        "  # Normalize `layer_query` to a list for consistent handling\n",
        "  if isinstance(layer_query, str):\n",
        "    layer_query = [layer_query]\n",
        "\n",
        "  # Add noise to the weights of the first attention layer\n",
        "  for layer_name, weights in modified_state_dict.items():\n",
        "    #print(f\"layer: {layer_name}\")\n",
        "    if layer_query is None or any(query in layer_name for query in layer_query):\n",
        "      print(f\"Bending {layer_name}...\")\n",
        "      noise = torch.randn(weights.size()) * noise_factor\n",
        "      modified_state_dict[layer_name] += noise\n",
        "\n",
        "  from transformers import AutoConfig, LlamaForCausalLM\n",
        "  # Create a new model with the modified weights\n",
        "  config = AutoConfig.from_pretrained(model.config.name_or_path)\n",
        "  modified_model = LlamaForCausalLM(config)\n",
        "  modified_model.load_state_dict(modified_state_dict)\n",
        "\n",
        "  print(\"Weights bent succesfully!\")\n",
        "  return modified_model\n",
        "\n",
        "# Save modified model to google drive\n",
        "def save_model_to_drive(model, path):\n",
        "  print(f\"Saving modified model to {path}...\")\n",
        "  model.save_pretrained(path)\n",
        "  print(\"Bent model saved succesfully!\")\n",
        "\n",
        "#Log experiment settings\n",
        "def log_experiment(model_name, layer_query, noise_factor, prompt, output):\n",
        "  timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "  layer_query_str = ', '.join(layer_query) if isinstance(layer_query, list) else layer_query\n",
        "\n",
        "  log_date = [\n",
        "      timestamp,\n",
        "      model_name,\n",
        "      layer_query_str,\n",
        "      noise_factor,\n",
        "      prompt,\n",
        "      output\n",
        "  ]\n",
        "\n",
        "  with open(log_file, 'a', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(log_date)\n",
        "\n",
        "def test_model(tokenizer, model, prompt=\"The quick brown fox\", max_length=50, temperature=1.0, top_k=50, top_p=0.9,repetition_penalty=1.0, layer_query='', noise_factor=0.0, name_modifier=None):\n",
        "  try:\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        temperature=temperature,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        do_sample=True\n",
        "    )\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"Output: {result}\")\n",
        "\n",
        "    # Log experiment settings\n",
        "    log_experiment(\n",
        "        model_name=model.config.name_or_path + name_modifier,\n",
        "        layer_query=layer_query,\n",
        "        noise_factor=noise_factor,\n",
        "        prompt=prompt,\n",
        "        output=result\n",
        "    )\n",
        "  except Exception as e:\n",
        "    print(f\"Error during testing: {e}\")"
      ],
      "metadata": {
        "id": "MnF9A9aPTpMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Load Model\n",
        "\n",
        "tokenizer, model = load_model_and_tokenizer_from_drive(drive_model_path)\n"
      ],
      "metadata": {
        "id": "-QczBUzaanHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7 (optional): Test original model\n",
        "\n",
        "name_modifier = '_repetition_penalty'\n",
        "test_model(tokenizer,model, prompt=\"Once upon a time\", max_length=150, temperature=.01, repetition_penalty=1.2, layer_query='None', noise_factor=0.0, name_modifier=name_modifier)\n"
      ],
      "metadata": {
        "id": "uDtrWeQHwDdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Modify model\n",
        "\n",
        "layer_query = ['self_attn.q_proj.weight']\n",
        "noise_factor = 0.03\n",
        "\n",
        "modified_model = bend_weights(model, noise_factor=noise_factor , layer_query=layer_query)\n",
        "test_model(tokenizer, modified_model, prompt=\"Once upon a time\", max_length=100, temperature=0.01, repetition_penalty=1.2, layer_query=layer_query, noise_factor=noise_factor, name_modifier=name_modifier)"
      ],
      "metadata": {
        "id": "WP_f0pHE_ggb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retest bent model (if you want to try other prompts)\n",
        "\n",
        "test_model(tokenizer, modified_model, prompt=\"Here are 5 creative ideas. Idea 1:\", max_length=150, temperature=.01, repetition_penalty=1.2, layer_query=layer_query, noise_factor=noise_factor, name_modifier=name_modifier)"
      ],
      "metadata": {
        "id": "j74DZHj4FDEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Save Modified model\n",
        "\n",
        "name = \"mlp.down_proj_0.01_exclamation\"\n",
        "save_model_to_drive(modified_model, modified_model_path + '_' + name)"
      ],
      "metadata": {
        "id": "ptG3vve7_wl8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}